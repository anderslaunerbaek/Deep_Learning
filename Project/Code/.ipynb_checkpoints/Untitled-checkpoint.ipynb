{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "--------------------------------------------\n",
      "conv1_1 \t (?, 224, 224, 64)\n",
      "conv1_2 \t (?, 224, 224, 64)\n",
      "pool1 \t\t (?, 112, 112, 64)\n",
      "--------------------------------------------\n",
      "conv2_1 \t (?, 112, 112, 128)\n",
      "conv2_2 \t (?, 112, 112, 128)\n",
      "pool2 \t\t (?, 56, 56, 128)\n",
      "--------------------------------------------\n",
      "conv3_1 \t (?, 56, 56, 256)\n",
      "conv3_2 \t (?, 56, 56, 256)\n",
      "conv3_3 \t (?, 56, 56, 256)\n",
      "pool3 \t\t (?, 28, 28, 256)\n",
      "--------------------------------------------\n",
      "conv4_1 \t (?, 28, 28, 512)\n",
      "conv4_2 \t (?, 28, 28, 512)\n",
      "conv4_3 \t (?, 28, 28, 512)\n",
      "pool4 \t\t (?, 14, 14, 512)\n",
      "--------------------------------------------\n",
      "conv5_1 \t (?, 14, 14, 512)\n",
      "conv5_2 \t (?, 14, 14, 512)\n",
      "conv5_3 \t (?, 14, 14, 512)\n",
      "pool5 \t\t (?, 7, 7, 512)\n",
      "--------------------------------------------\n",
      "flatten \t (?, 25088)\n",
      "fc6 \t\t (?, 4096)\n",
      "fc7 \t\t (?, 4096)\n",
      "fc8 \t\t (?, 6)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 21 16:24:01 2017\n",
    "\n",
    "@author: s160159\n",
    "\"\"\"\n",
    "\n",
    "## import ----\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils\n",
    "import utils_s160159 as u_s\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "## load data ----\n",
    "VERSION = '3.0'\n",
    "FILENAME = 'master'\n",
    "data_dir = './../Data'\n",
    "logs_path = './logs'\n",
    "NUM_SUBJECTS = 2\n",
    "NUM_CLASSES = 6\n",
    "VAL_TRAIN_ID = NUM_SUBJECTS - 4\n",
    "\n",
    "# load all subjects into memory\n",
    "subjects_list = []\n",
    "## Load\n",
    "for ii in range(1,NUM_SUBJECTS+1):\n",
    "    print(\"Loading subject %d of %d...\" %(ii, NUM_SUBJECTS), end='\\r')\n",
    "    tmp = np.load(data_dir + '_dicts' + '/subject_' + str(ii) + '_dict.npy').item()\n",
    "    \n",
    "    tmp_one = np.zeros((len(tmp[1]),NUM_CLASSES))\n",
    "    #tmp_one[:] = -1\n",
    "    for jj in range(len(tmp[1])):\n",
    "        tmp_one[jj][tmp[1][jj]] = 1\n",
    "    \n",
    "    subjects_list.append([tmp[0], tmp_one])\n",
    "# extract image shapes\n",
    "IMAGE_SHAPE = subjects_list[0][0].shape\n",
    "\n",
    "## Building the model ----\n",
    "# hyper parameters\n",
    "HEIGTH, WIDTH, NCHANNELS = IMAGE_SHAPE[1], IMAGE_SHAPE[2], IMAGE_SHAPE[3]\n",
    "L_RATE = 10e-5\n",
    "L_RATE_MO_1 = 0.9\n",
    "L_RATE_MO_2 = 0.999\n",
    "EPS = 1e-8\n",
    "KEEP_PROB = 0.5\n",
    "# Training Loop\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 250 #\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = False\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "\n",
    "# https://www.cs.toronto.edu/~frossard/vgg16/vgg16.py\n",
    "# Load the weights into memory\n",
    "weights_dict = np.load(data_dir + '/' + 'vgg16_weights.npz', encoding='bytes')\n",
    "\n",
    "def tf_conv2d(inputs, name):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        weights = tf.get_variable(shape=weights_dict[name + '_W'].shape, \n",
    "                                  initializer=tf.constant_initializer(weights_dict[name + '_W']),\n",
    "                                  name=scope + 'weights', \n",
    "                                  trainable=False)\n",
    "        conv = tf.nn.conv2d(inputs, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.get_variable(shape=weights_dict[name + '_b'].shape,\n",
    "                                 initializer=tf.constant_initializer(weights_dict[name + '_b']), \n",
    "                                 trainable=False, name=scope + 'biases')\n",
    "        return(tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope))\n",
    "        \n",
    "def tf_max_pooling2d(inputs, name, kh = 2, kw = 2, dh = 2, dw = 2):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        return(tf.nn.max_pool(inputs,\n",
    "                              ksize=[1, kh, kw, 1],\n",
    "                              strides=[1, dh, dw, 1],\n",
    "                              padding='VALID',\n",
    "                              name=scope))        \n",
    "\n",
    "def tf_fully_con(inputs, name, n_out=4096, train_able = True):\n",
    "    n_in = n_in = inputs.get_shape()[-1].value\n",
    "    with tf.name_scope(name) as scope:\n",
    "        if train_able:\n",
    "            weights = tf.get_variable(shape=[n_in, n_out],\n",
    "                                      dtype=tf.float32,\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      name=scope + 'weights', \n",
    "                                      trainable=True)\n",
    "\n",
    "            biases = tf.get_variable(shape=n_out,\n",
    "                                     dtype=tf.float32,\n",
    "                                     initializer=tf.constant_initializer(0.0),\n",
    "                                     trainable=True, \n",
    "                                     name=scope + 'biases')\n",
    "        else:\n",
    "            weights = tf.get_variable(shape=[n_in, n_out],\n",
    "                                      dtype=tf.float32,\n",
    "                                      initializer=tf.constant_initializer(weights_dict[name + '_W']), \n",
    "                                      name=scope + 'weights', \n",
    "                                      trainable=False)\n",
    "\n",
    "            biases = tf.get_variable(shape=n_out,\n",
    "                                     dtype=tf.float32,\n",
    "                                     initializer=tf.constant_initializer(weights_dict[name + '_b']), \n",
    "                                     trainable=False, \n",
    "                                     name=scope + 'biases')\n",
    "        \n",
    "        #\n",
    "        return(tf.nn.relu(tf.nn.bias_add(tf.matmul(inputs, weights), biases)))\n",
    "        \n",
    "# https://github.com/huyng/tensorflow-vgg/blob/master/layers.py\n",
    "# init model\n",
    "tf.reset_default_graph()\n",
    "# init placeholders\n",
    "x_pl = tf.placeholder(tf.float32, [None, HEIGTH, WIDTH, NCHANNELS], name='input_placeholder')\n",
    "y_pl = tf.placeholder(tf.float32, [None, NUM_CLASSES], name='target_placeholder')\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('--------------------------------------------')\n",
    "with tf.variable_scope('VVG16_layer'):\n",
    "    # subtract image mean\n",
    "    #mu = tf.constant(np.array([115.79640507,127.70359263,119.96839583], dtype=np.float32), \n",
    "    #                 name=\"rgb_mean\")\n",
    "    #net = tf.subtract(x_pl, mu, name=\"input_mean_centered\")\n",
    "    \n",
    "    # level one\n",
    "    net = tf_conv2d(inputs=x_pl, name='conv1_1')\n",
    "    #net = tf_conv2d(inputs=net, name='conv1_1')\n",
    "    print('conv1_1 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv1_2')\n",
    "    print('conv1_2 \\t', net.get_shape())\n",
    "    net = tf_max_pooling2d(inputs=net, name='pool1')\n",
    "    print('pool1 \\t\\t', net.get_shape())\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    # level two\n",
    "    net = tf_conv2d(inputs=net, name='conv2_1')\n",
    "    print('conv2_1 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv2_2')\n",
    "    print('conv2_2 \\t', net.get_shape())\n",
    "    net = tf_max_pooling2d(inputs=net, name='pool2')\n",
    "    print('pool2 \\t\\t', net.get_shape())\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    # level three\n",
    "    net = tf_conv2d(inputs=net, name='conv3_1')\n",
    "    print('conv3_1 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv3_2')\n",
    "    print('conv3_2 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv3_3')\n",
    "    print('conv3_3 \\t', net.get_shape())\n",
    "    net = tf_max_pooling2d(inputs=net, name='pool_3')\n",
    "    print('pool3 \\t\\t', net.get_shape())\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    # level four\n",
    "    net = tf_conv2d(inputs=net, name='conv4_1')\n",
    "    print('conv4_1 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv4_2')\n",
    "    print('conv4_2 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv4_3')\n",
    "    print('conv4_3 \\t', net.get_shape())\n",
    "    net = tf_max_pooling2d(inputs=net, name='pool_4')\n",
    "    print('pool4 \\t\\t', net.get_shape())\n",
    "    print('--------------------------------------------')\n",
    "\n",
    "    # level five\n",
    "    net = tf_conv2d(inputs=net, name='conv5_1')\n",
    "    print('conv5_1 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv5_2')\n",
    "    print('conv5_2 \\t', net.get_shape())\n",
    "    net = tf_conv2d(inputs=net, name='conv5_3')\n",
    "    print('conv5_3 \\t', net.get_shape())\n",
    "    net = tf_max_pooling2d(inputs=net, name='pool_5')\n",
    "    print('pool5 \\t\\t', net.get_shape())\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    \n",
    "    # flatten\n",
    "    flattened_shape = np.prod([s.value for s in net.get_shape()[1:]])\n",
    "    net = tf.reshape(net, [-1, flattened_shape], name=\"flatten\")\n",
    "    print('flatten \\t', net.get_shape())\n",
    "    # level six\n",
    "    net = tf_fully_con(inputs=net, name='fc6', n_out=4096)\n",
    "    print('fc6 \\t\\t', net.get_shape())\n",
    "    net = tf.layers.dropout(inputs=net, name='fc6_dropout', rate=KEEP_PROB)\n",
    "\n",
    "    # level seven\n",
    "    net = tf_fully_con(inputs=net, name='fc7', n_out=4096)\n",
    "    print('fc7 \\t\\t', net.get_shape())\n",
    "    net = tf.layers.dropout(inputs=net, name='fc7_dropout', rate=KEEP_PROB)\n",
    "\n",
    "    # level eigth\n",
    "    logits = tf_fully_con(inputs=net, name='fc8', n_out=NUM_CLASSES)\n",
    "    print('fc8 \\t\\t', logits.get_shape()) \n",
    "    print('--------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
